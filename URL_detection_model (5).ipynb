{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586c34f-3f76-4a4e-b41f-7081c9cf106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy scikit-learn tldextract joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba563b14-2003-4b42-9ec7-6d601a2702cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tldextract \n",
    "import joblib  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2fddc9-93c6-4fa0-8454-9cd22c8f616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\froze\\Downloads\\archive (7)\\malicious_phish.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8370f2f-f3ca-4389-b62c-55c157d8ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=len(df), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc89e9-1ec3-47d9-b96d-a48df86cbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7001e-14cd-46aa-9522-9ce6aaba321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']= df['type'].apply(lambda x :0 if x=='benign' else 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c9899-edae-446d-aad3-3ccf1191bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e2b61-77d5-4a00-a800-0cf6eb9e97ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import tldextract\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "def url_entropy(url):\n",
    "    \"\"\"Calculate Shannon entropy of the URL.\"\"\"\n",
    "    if not url:\n",
    "        return 0\n",
    "    freq = {c: url.count(c) for c in set(url)}\n",
    "    return -sum((f / len(url)) * math.log2(f / len(url)) for f in freq.values())\n",
    "\n",
    "def extract_features(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    extracted = tldextract.extract(url)\n",
    "    \n",
    "    features = {\n",
    "        'url_length': len(url),\n",
    "        'domain_length': len(extracted.domain),\n",
    "        'tld': extracted.suffix,\n",
    "        'has_ip': 1 if re.match(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', parsed_url.netloc) else 0,\n",
    "        'num_dots': url.count('.'),\n",
    "        'num_hyphens': url.count('-'),\n",
    "        'num_digits': sum(c.isdigit() for c in url),\n",
    "        'num_subdomains': len(extracted.subdomain.split('.')) if extracted.subdomain else 0,\n",
    "        'has_https': 1 if parsed_url.scheme == 'https' else 0,\n",
    "        'has_at': 1 if '@' in url else 0,\n",
    "        'has_redirect': 1 if '//' in parsed_url.path else 0,\n",
    "    }\n",
    "    \n",
    "  \n",
    "    features['entropy'] = url_entropy(url)\n",
    "    \n",
    "    suspicious_keywords = [\n",
    "        'login', 'bank', 'update', 'secure', 'verify', \n",
    "        'account', 'paypal', 'amazon', 'malicious', 'phish'\n",
    "    ]\n",
    "    features['num_suspicious_keywords'] = sum(1 for kw in suspicious_keywords if kw in url.lower())\n",
    "    \n",
    "    features['num_special_chars'] = sum(1 for c in url if c in '?=&%')\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "def normalize_url(url):\n",
    "    parsed = urlparse(url)\n",
    "    netloc = parsed.netloc.replace('www.', '')  # Remove 'www.'\n",
    "    return netloc + parsed.path + parsed.params + parsed.query  # Rebuild without scheme\n",
    "\n",
    "df['url'] = df['url'].apply(normalize_url)\n",
    "\n",
    "\n",
    "feature_list = df['url'].apply(extract_features).tolist()\n",
    "df_features = pd.DataFrame(feature_list)\n",
    "df_features['label'] = df['label']  \n",
    "\n",
    "\n",
    "top_tlds = df_features['tld'].value_counts().index[:20]\n",
    "df_features['tld'] = df_features['tld'].apply(lambda x: x if x in top_tlds else 'other')\n",
    "df_features = pd.get_dummies(df_features, columns=['tld'])\n",
    "\n",
    "df_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72a2f2-85ab-404a-81fc-836637cbe8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features.drop('label', axis=1)\n",
    "y=df_features['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ff5ae-f1e9-4e32-8764-b415d1265ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model= RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f77b86-5854-43e6-ad7f-b5620fbdc079",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a0de4c-84da-4f0e-8b18-c36b7d1cae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6df9f-7a50-419c-a6eb-8609339e320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282b5ab-9729-49d6-9401-1e16e511f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_columns = X.columns.tolist()\n",
    "expected_columns\n",
    "joblib.dump(expected_columns, 'expected_columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d4d62-1094-46a5-8e4e-fc2340c1c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'URL_detection_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7519b-f969-42a9-a4ff-cb60ea62b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tlds\n",
    "joblib.dump(top_tlds, 'top_tlds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f965a64-ed1a-43ab-85b9-dc5a30a5edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=joblib.load('URL_detection_model.pkl')\n",
    "top_tlds = joblib.load('top_tlds.pkl')\n",
    "expected_columns = joblib.load('expected_columns.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08902f9e-4ab1-49fb-82df-9a9e4bb7b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc04d1-fd1e-4d1e-b8a8-5a0d5d0e63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d20ef7-e8f1-46e4-840d-4d0916317f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_url(url):\n",
    "    custom_features=extract_features(url)\n",
    "    custom_df=pd.DataFrame([custom_features])\n",
    "\n",
    "    custom_df['tld']=custom_df['tld'].apply(lambda x: x if x in top_tlds else 'other')\n",
    "    custom_df=pd.get_dummies(custom_df,columns=['tld'])\n",
    "\n",
    "\n",
    "    for col in expected_columns:\n",
    "        if col not in custom_df.columns:\n",
    "            custom_df[col]=0\n",
    "    custom_df = custom_df[expected_columns]\n",
    "\n",
    "    prediction=model.predict(custom_df)\n",
    "    probability=model.predict_proba(custom_df)\n",
    "\n",
    "    label = \"Benign\" if prediction[0] == 0 else \"Malicious\"\n",
    "    prob_benign = probability[0][0]\n",
    "    prob_malicious = probability[0][1]\n",
    "\n",
    "    return label, prob_benign, prob_malicious\n",
    "\n",
    "\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b326492-b373-4bc3-981d-4661d5f6ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d3d37-3f36-4638-8a92-885b026f54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57390727-4415-4f5d-975b-19c2660a4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing cell\n",
    "urls_to_test = [\n",
    "    \"https://google.com\",\n",
    "    \"https://www.wikipedia.org\",\n",
    "    \"https://github.com\",\n",
    "    \"https://www.khanacademy.org\",\n",
    "    \"https://www.stackoverflow.com\",\n",
    "    \"https://www.microsoft.com/en-us\",\n",
    "    \"https://www.nytimes.com\",\n",
    "    \"https://www.researchgate.net\",\n",
    "    \"https://www.bbc.com/news\",\n",
    "    \"https://www.coursera.org\",\n",
    "    \"http://example-malicious-site.com/login?fake=1\",\n",
    "    \"http://192.168.1.1/malware.exe\",\n",
    "    \"http://update-banking-info.xyz\",\n",
    "    \"http://secure-paypal-login.com/verify\",\n",
    "    \"http://amazon-login-security-update.net\",\n",
    "    \"http://free-gift-card-reward.click\",\n",
    "    \"http://bankofamerica.verify-user.info/login\",\n",
    "    \"http://phishing-site.ru/account/update\",\n",
    "    \"http://cheap-luxury-products.cn/paypal\",\n",
    "    \"http://darkweb-marketplace.onion\"\n",
    "]\n",
    "\n",
    "    \n",
    "for url in urls_to_test:\n",
    "    label, prob_benign, prob_malicious = custom_url(url)\n",
    "    print(f\"URL: {url}\")\n",
    "    print(f\"Prediction: {label}\")\n",
    "    print(f\"Probability (Benign): {prob_benign:.2f}\")\n",
    "    print(f\"Probability (Malicious): {prob_malicious:.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
